{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_bert__xxj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8395fc6e66f24f06ab08afbd0fdf209b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e7d63efcfa324decac04f300d18b2445",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a330b07eb91a43a7a5120e0e54c9f7fa",
              "IPY_MODEL_9245691a4a30468c8330ea2c7e5f6f77"
            ]
          }
        },
        "e7d63efcfa324decac04f300d18b2445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a330b07eb91a43a7a5120e0e54c9f7fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e60583b08f5741d190cdf1733bf9126b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 109540,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 109540,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3fdf847fb62845f2b67768809ba0a4bd"
          }
        },
        "9245691a4a30468c8330ea2c7e5f6f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a3e5a1a00204eac9d3df889f5c00e5a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 110k/110k [00:00&lt;00:00, 1.11MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c2fb06073434f9a86a6b0b2d36eda98"
          }
        },
        "e60583b08f5741d190cdf1733bf9126b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3fdf847fb62845f2b67768809ba0a4bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a3e5a1a00204eac9d3df889f5c00e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c2fb06073434f9a86a6b0b2d36eda98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDSzDlA6gYg4",
        "colab_type": "code",
        "outputId": "eddf8c38-8595-4ae4-9726-6f4b7f697eb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow==2.1.0\n",
        "!pip install tensorflow-gpu\n",
        "!pip install transformers\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 34kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.18.3)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 47.5MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 42.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.28.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.1.0) (46.1.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.7.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.4.5.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=2fdd47c280b5722fe09d715c9eb3eaf59fe99884504f4c873e84c6c7ddfef3ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0rc3\n",
            "    Uninstalling tensorflow-2.2.0rc3:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc3\n",
            "Successfully installed gast-0.2.2 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n",
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/93/c7bca39b23aae45cd2e85ad3871c81eccc63b9c5276e926511e2e5b0879d/tensorflow_gpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 35kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.1.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.2.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.28.1)\n",
            "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.1.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu) (46.1.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.2.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.1.0\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 16.1MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 14.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 49.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.47)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=a836b97608e1efa8105c9aaa04521c6359a0af675e032544f5906f4dc41979c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz0VCZtfODZQ",
        "colab_type": "code",
        "outputId": "9520111e-5cfd-4b7b-aaf9-ee0194bab2a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.utils import to_categorical\n",
        "import os\n",
        "import six\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import *\n",
        "import transformers\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfv2deuZp4Ih",
        "colab_type": "code",
        "outputId": "2659f557-4521-4236-fe3e-c06c232a3547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "PATH ='/content/drive/My Drive/Colab Notebooks/data'\n",
        "MAX_SEQUENCE_LENGTH = 150\n",
        "input_categories = '微博中文内容'\n",
        "output_categories = '情感倾向'\n",
        "df_train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/nCoV_100k_train.labled.csv')\n",
        "df_train = df_train[df_train[output_categories].isin(['-1','0','1'])]\n",
        "df_test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/nCov_10k_test.csv')\n",
        "df_sub = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/submit_example.csv')\n",
        "print('train shape =', df_train.shape)\n",
        "print('test shape =', df_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape = (99913, 7)\n",
            "test shape = (10000, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm85OilDK67X",
        "colab_type": "code",
        "outputId": "b0ec86a8-e853-4296-a5fc-409aef67e5e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df_train.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['微博id', '微博发布时间', '发布人账号', '微博中文内容', '微博图片', '微博视频', '情感倾向'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBc4nftDsZHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _convert_to_transformer_inputs(instance, tokenizer, max_sequence_length):\n",
        "    \"\"\"Converts tokenized input to ids, masks and segments for transformer (including bert)\"\"\"\n",
        "    \n",
        "    def return_id(str1, truncation_strategy, length):\n",
        "\n",
        "        inputs = tokenizer.encode_plus(str1,\n",
        "            add_special_tokens=True,\n",
        "            max_length=length,\n",
        "            truncation_strategy=truncation_strategy)\n",
        "        \n",
        "        input_ids =  inputs[\"input_ids\"]\n",
        "        input_masks = [1] * len(input_ids)\n",
        "        input_segments = inputs[\"token_type_ids\"]\n",
        "        padding_length = length - len(input_ids)\n",
        "        padding_id = tokenizer.pad_token_id\n",
        "        input_ids = input_ids + ([padding_id] * padding_length)\n",
        "        input_masks = input_masks + ([0] * padding_length)\n",
        "        input_segments = input_segments + ([0] * padding_length)\n",
        "        \n",
        "        return [input_ids, input_masks, input_segments]\n",
        "    \n",
        "    input_ids, input_masks, input_segments = return_id(\n",
        "        instance, 'longest_first', max_sequence_length)\n",
        "    \n",
        "    return [input_ids, input_masks, input_segments]\n",
        "\n",
        "def compute_input_arrays(df, columns, tokenizer, max_sequence_length):\n",
        "    input_ids, input_masks, input_segments = [], [], []\n",
        "    for instance in tqdm(df[columns]):\n",
        "        \n",
        "        ids, masks, segments = \\\n",
        "        _convert_to_transformer_inputs(str(instance), tokenizer, max_sequence_length)\n",
        "        \n",
        "        input_ids.append(ids)\n",
        "        input_masks.append(masks)\n",
        "        input_segments.append(segments)\n",
        "\n",
        "    return [np.asarray(input_ids, dtype=np.int32), \n",
        "            np.asarray(input_masks, dtype=np.int32), \n",
        "            np.asarray(input_segments, dtype=np.int32)\n",
        "           ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ooqnwvcvr1R",
        "colab_type": "code",
        "outputId": "bf3b2263-d225-4d0b-bef4-6dfbc2cee43b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "8395fc6e66f24f06ab08afbd0fdf209b",
            "e7d63efcfa324decac04f300d18b2445",
            "a330b07eb91a43a7a5120e0e54c9f7fa",
            "9245691a4a30468c8330ea2c7e5f6f77",
            "e60583b08f5741d190cdf1733bf9126b",
            "3fdf847fb62845f2b67768809ba0a4bd",
            "1a3e5a1a00204eac9d3df889f5c00e5a",
            "4c2fb06073434f9a86a6b0b2d36eda98"
          ]
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
        "inputs = compute_input_arrays(df_train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n",
        "test_inputs = compute_input_arrays(df_test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8395fc6e66f24f06ab08afbd0fdf209b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=109540, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 256/99913 [00:00<00:38, 2556.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 99913/99913 [00:53<00:00, 1852.44it/s]\n",
            "100%|██████████| 10000/10000 [00:05<00:00, 1874.44it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBAgO_GFECGl",
        "colab_type": "code",
        "outputId": "f02391ba-11e0-439b-822a-a08d5ed61f3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "inputs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 101, 1091, 1762, ...,    0,    0,    0],\n",
              "        [ 101, 2458, 2399, ...,    0,    0,    0],\n",
              "        [ 101, 6937, 3247, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [ 101,  108, 2544, ...,    0,    0,    0],\n",
              "        [ 101,  523, 3173, ...,    0,    0,    0],\n",
              "        [ 101,  794, 6073, ...,    0,    0,    0]], dtype=int32),\n",
              " array([[1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0]], dtype=int32),\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=int32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MIXuVarv0zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_output_arrays(df, columns):\n",
        "    return np.asarray(df[columns].astype(int) + 1)\n",
        "outputs = compute_output_arrays(df_train, output_categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPWhG2mBwCTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    input_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)    \n",
        "    input_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)    \n",
        "    input_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32) \n",
        "    config = BertConfig.from_pretrained('bert-base-chinese')\n",
        "    bert_model = TFBertModel.from_pretrained('bert-base-chinese',config=config)\n",
        "    embedding = bert_model(input_id, attention_mask=input_mask, token_type_ids=input_atn)[0]   \n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(embedding)    \n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    x = tf.keras.layers.Dense(3, activation='softmax',name='class_out')(x)\n",
        "    model = tf.keras.models.Model(inputs=[input_id, input_mask, input_atn], outputs=x)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuB5NRQawET4",
        "colab_type": "code",
        "outputId": "3c030ea5-91c5-40ea-dd43-489e1b657cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gkf = StratifiedKFold(n_splits=5,shuffle=True,random_state=0).split(X=df_train[input_categories].fillna('-1'), y=df_train[output_categories].fillna('-1'))\n",
        "valid_preds = []\n",
        "test_preds = []\n",
        "for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
        "        train_inputs = [inputs[i][train_idx] for i in range(len(inputs))]\n",
        "        train_outputs = to_categorical(outputs[train_idx])\n",
        "        valid_inputs = [inputs[i][valid_idx] for i in range(len(inputs))]\n",
        "        valid_outputs = to_categorical(outputs[valid_idx])\n",
        "        K.clear_session()\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
        "        model = create_model()\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc', 'mae'])\n",
        "        model.summary()\n",
        "        model.fit(train_inputs, train_outputs, validation_data= [valid_inputs, valid_outputs], epochs=1,batch_size=64)\n",
        "        valid_preds.append(model.predict(valid_inputs))\n",
        "        test_preds.append(model.predict(test_inputs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     ((None, 150, 768), ( 102267648   input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 768)          0           global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "class_out (Dense)               (None, 3)            2307        dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 102,269,955\n",
            "Trainable params: 102,269,955\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 89921 samples, validate on 9992 samples\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "89921/89921 [==============================] - 1579s 18ms/sample - loss: 0.6091 - acc: 0.7338 - mae: 0.2323 - val_loss: 0.5433 - val_acc: 0.7641 - val_mae: 0.2111\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     ((None, 150, 768), ( 102267648   input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 768)          0           global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "class_out (Dense)               (None, 3)            2307        dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 102,269,955\n",
            "Trainable params: 102,269,955\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 89921 samples, validate on 9992 samples\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "89921/89921 [==============================] - 1580s 18ms/sample - loss: 0.5969 - acc: 0.7382 - mae: 0.2313 - val_loss: 0.5640 - val_acc: 0.7475 - val_mae: 0.2248\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     ((None, 150, 768), ( 102267648   input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 768)          0           global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "class_out (Dense)               (None, 3)            2307        dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 102,269,955\n",
            "Trainable params: 102,269,955\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 89921 samples, validate on 9992 samples\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "89921/89921 [==============================] - 1580s 18ms/sample - loss: 0.6017 - acc: 0.7363 - mae: 0.2317 - val_loss: 0.5586 - val_acc: 0.7608 - val_mae: 0.2068\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     ((None, 150, 768), ( 102267648   input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 768)          0           global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "class_out (Dense)               (None, 3)            2307        dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 102,269,955\n",
            "Trainable params: 102,269,955\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 89922 samples, validate on 9991 samples\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "89922/89922 [==============================] - 1581s 18ms/sample - loss: 0.6012 - acc: 0.7353 - mae: 0.2311 - val_loss: 0.5852 - val_acc: 0.7409 - val_mae: 0.2200\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     ((None, 150, 768), ( 102267648   input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 768)          0           global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "class_out (Dense)               (None, 3)            2307        dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 102,269,955\n",
            "Trainable params: 102,269,955\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 89922 samples, validate on 9991 samples\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "89922/89922 [==============================] - 1581s 18ms/sample - loss: 0.6064 - acc: 0.7338 - mae: 0.2311 - val_loss: 0.5695 - val_acc: 0.7535 - val_mae: 0.2103\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     ((None, 150, 768), ( 102267648   input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 768)          0           global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "class_out (Dense)               (None, 3)            2307        dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 102,269,955\n",
            "Trainable params: 102,269,955\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 89922 samples, validate on 9991 samples\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "89922/89922 [==============================] - 1581s 18ms/sample - loss: 0.5982 - acc: 0.7375 - mae: 0.2316 - val_loss: 0.5464 - val_acc: 0.7609 - val_mae: 0.2114\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     ((None, 150, 768), ( 102267648   input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 768)          0           global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "class_out (Dense)               (None, 3)            2307        dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 102,269,955\n",
            "Trainable params: 102,269,955\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 89922 samples, validate on 9991 samples\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "89922/89922 [==============================] - 1580s 18ms/sample - loss: 0.5992 - acc: 0.7381 - mae: 0.2313 - val_loss: 0.5678 - val_acc: 0.7517 - val_mae: 0.2079\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     ((None, 150, 768), ( 102267648   input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 768)          0           global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "class_out (Dense)               (None, 3)            2307        dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 102,269,955\n",
            "Trainable params: 102,269,955\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 89922 samples, validate on 9991 samples\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "89922/89922 [==============================] - 1580s 18ms/sample - loss: 0.6033 - acc: 0.7368 - mae: 0.2314 - val_loss: 0.5994 - val_acc: 0.7306 - val_mae: 0.2307\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     ((None, 150, 768), ( 102267648   input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 768)          0           global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "class_out (Dense)               (None, 3)            2307        dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 102,269,955\n",
            "Trainable params: 102,269,955\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 89922 samples, validate on 9991 samples\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "89922/89922 [==============================] - 1580s 18ms/sample - loss: 0.6078 - acc: 0.7346 - mae: 0.2309 - val_loss: 0.5573 - val_acc: 0.7530 - val_mae: 0.2182\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 150)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     ((None, 150, 768), ( 102267648   input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 768)          0           tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 768)          0           global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "class_out (Dense)               (None, 3)            2307        dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 102,269,955\n",
            "Trainable params: 102,269,955\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 89922 samples, validate on 9991 samples\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "89922/89922 [==============================] - 1579s 18ms/sample - loss: 0.6067 - acc: 0.7350 - mae: 0.2317 - val_loss: 0.5563 - val_acc: 0.7575 - val_mae: 0.2125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uImzJdYQ6lXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OptimizedRounder(object):\n",
        "    def __init__(self):\n",
        "        self.coef_ = [1.,1.,1.]\n",
        "    def _kappa_loss(self, coef, X, y):\n",
        "        X_p = np.copy(X)\n",
        "        X_p = np.argmax(X_p*coef,axis=1)\n",
        "        y_t = np.argmax(y,axis=1)\n",
        "        ll = f1_score(y_t, X_p,average='macro')\n",
        "        print('f1 score: ',ll)\n",
        "        return -ll\n",
        "    def fit(self, X, y):\n",
        "        loss_partial = partial(self._kappa_loss, X=X, y=y)\n",
        "        if type(self.coef_) is list:\n",
        "          initial_coef = self.coef_\n",
        "        else:\n",
        "          initial_coef = self.coef_['x']\n",
        "        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef,method='Nelder-Mead')\n",
        "    def predict(self, X, coef):\n",
        "        X_p = np.copy(X)\n",
        "        X_p = np.argmax(X_p*coef,axis=1)\n",
        "        return X_p\n",
        "    def coefficients(self):\n",
        "        return self.coef_['x']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_9T5iR7PX2f",
        "colab_type": "code",
        "outputId": "e8cdb51e-df83-4aa6-8b1b-0cdc2891edc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(valid_preds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Puf8JzceDCW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opr = OptimizedRounder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYtl-0RfDMtM",
        "colab_type": "code",
        "outputId": "f6c17465-7088-4598-afbf-03768d00bb02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gkf = StratifiedKFold(n_splits=5,shuffle=True,random_state=0).split(X=df_train[input_categories].fillna('-1'), y=df_train[output_categories].fillna('-1'))\n",
        "for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
        "  print('flod: ',fold)\n",
        "  valid_outputs = to_categorical(outputs[valid_idx])\n",
        "  opr.fit(X=valid_preds[fold],y=valid_outputs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "flod:  0\n",
            "f1 score:  0.7229792996734314\n",
            "f1 score:  0.7236591941826706\n",
            "f1 score:  0.720171353803464\n",
            "f1 score:  0.7254160081231914\n",
            "f1 score:  0.728543059257044\n",
            "f1 score:  0.732195289360769\n",
            "f1 score:  0.7310862046336348\n",
            "f1 score:  0.7319496321039004\n",
            "f1 score:  0.7362101285300638\n",
            "f1 score:  0.7378396718366371\n",
            "f1 score:  0.7391343911984917\n",
            "f1 score:  0.7370411614890502\n",
            "f1 score:  0.737626000384937\n",
            "f1 score:  0.7317587397042998\n",
            "f1 score:  0.7356894674945341\n",
            "f1 score:  0.7357672395007363\n",
            "f1 score:  0.7368900827181574\n",
            "f1 score:  0.7383573319856732\n",
            "f1 score:  0.7371830847561324\n",
            "f1 score:  0.7380849736529592\n",
            "f1 score:  0.7376615722808886\n",
            "f1 score:  0.7376824992661705\n",
            "f1 score:  0.7389393234665157\n",
            "f1 score:  0.7377934894320429\n",
            "f1 score:  0.7377910359448601\n",
            "f1 score:  0.7375309635070981\n",
            "f1 score:  0.7386685988603517\n",
            "f1 score:  0.7376999237214062\n",
            "f1 score:  0.7386428850621333\n",
            "f1 score:  0.7375291315111799\n",
            "f1 score:  0.739013410532666\n",
            "f1 score:  0.7375367378905301\n",
            "f1 score:  0.739013410532666\n",
            "f1 score:  0.7385602408906872\n",
            "f1 score:  0.738960086967314\n",
            "f1 score:  0.7387555941871445\n",
            "f1 score:  0.7393182820510263\n",
            "f1 score:  0.7390826779494265\n",
            "f1 score:  0.7378524364341331\n",
            "f1 score:  0.7394349404167156\n",
            "f1 score:  0.7390625406583178\n",
            "f1 score:  0.7392836106869689\n",
            "f1 score:  0.7390509592998269\n",
            "f1 score:  0.7393094834987669\n",
            "f1 score:  0.739120523838522\n",
            "f1 score:  0.7392836106869689\n",
            "f1 score:  0.7392186872896674\n",
            "f1 score:  0.7392603583129693\n",
            "f1 score:  0.7392344961157611\n",
            "f1 score:  0.7392861866589131\n",
            "f1 score:  0.7390769792360533\n",
            "f1 score:  0.7392603583129693\n",
            "f1 score:  0.7390769792360533\n",
            "f1 score:  0.7392603583129693\n",
            "f1 score:  0.7391607508320459\n",
            "f1 score:  0.7391607508320459\n",
            "f1 score:  0.7391607508320459\n",
            "f1 score:  0.7391607508320459\n",
            "f1 score:  0.7391607508320459\n",
            "f1 score:  0.7391607508320459\n",
            "f1 score:  0.7390511180024072\n",
            "f1 score:  0.7390511180024072\n",
            "f1 score:  0.7391607508320459\n",
            "f1 score:  0.7394608018747957\n",
            "f1 score:  0.7393611889110886\n",
            "f1 score:  0.7394608018747957\n",
            "f1 score:  0.7392357599619318\n",
            "f1 score:  0.7392515490396683\n",
            "f1 score:  0.7391607508320459\n",
            "f1 score:  0.7393611889110886\n",
            "f1 score:  0.7393108109260472\n",
            "f1 score:  0.7394608018747957\n",
            "f1 score:  0.7394608018747957\n",
            "f1 score:  0.7394608018747957\n",
            "f1 score:  0.7394608018747957\n",
            "f1 score:  0.7394608018747957\n",
            "f1 score:  0.7394608018747957\n",
            "f1 score:  0.7394608018747957\n",
            "f1 score:  0.7394608018747957\n",
            "f1 score:  0.7394608018747957\n",
            "f1 score:  0.7394608018747957\n",
            "f1 score:  0.7394608018747957\n",
            "f1 score:  0.7394608018747957\n",
            "f1 score:  0.7394608018747957\n",
            "flod:  1\n",
            "f1 score:  0.7149682304141036\n",
            "f1 score:  0.7130395655914015\n",
            "f1 score:  0.7175822843570105\n",
            "f1 score:  0.7125960297610444\n",
            "f1 score:  0.7170868413789767\n",
            "f1 score:  0.7195643010505314\n",
            "f1 score:  0.7213294879647414\n",
            "f1 score:  0.7202929745160054\n",
            "f1 score:  0.7235597307713687\n",
            "f1 score:  0.7254289486122208\n",
            "f1 score:  0.7263719935394759\n",
            "f1 score:  0.72940525984137\n",
            "f1 score:  0.7280636638280932\n",
            "f1 score:  0.729625818165006\n",
            "f1 score:  0.7252208889400439\n",
            "f1 score:  0.7306741569568901\n",
            "f1 score:  0.7194993472986009\n",
            "f1 score:  0.7319528716965072\n",
            "f1 score:  0.7279126283478262\n",
            "f1 score:  0.7172984480673645\n",
            "f1 score:  0.7301927213670889\n",
            "f1 score:  0.7307939376221141\n",
            "f1 score:  0.7268568527225708\n",
            "f1 score:  0.7303446249280748\n",
            "f1 score:  0.7306145801056921\n",
            "f1 score:  0.730853058645967\n",
            "f1 score:  0.7327480489961937\n",
            "f1 score:  0.7307979681354425\n",
            "f1 score:  0.7304931915563176\n",
            "f1 score:  0.7329043089525372\n",
            "f1 score:  0.732029949823442\n",
            "f1 score:  0.7312997790329666\n",
            "f1 score:  0.7320294856893508\n",
            "f1 score:  0.7327415983699561\n",
            "f1 score:  0.7323357904813691\n",
            "f1 score:  0.7324861001460601\n",
            "f1 score:  0.7324593217546411\n",
            "f1 score:  0.7328541939473454\n",
            "f1 score:  0.732258154387604\n",
            "f1 score:  0.7338027561548118\n",
            "f1 score:  0.7319828239978926\n",
            "f1 score:  0.7331690447655039\n",
            "f1 score:  0.7328517153205804\n",
            "f1 score:  0.7333248053726623\n",
            "f1 score:  0.732859755542079\n",
            "f1 score:  0.733164177161529\n",
            "f1 score:  0.7336618310431212\n",
            "f1 score:  0.7333897237161451\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7326334354288274\n",
            "f1 score:  0.7337665091764513\n",
            "f1 score:  0.7332651002384035\n",
            "f1 score:  0.7336500239553737\n",
            "f1 score:  0.7336630161019961\n",
            "f1 score:  0.7340515266330904\n",
            "f1 score:  0.7342589315336406\n",
            "f1 score:  0.7337788625231404\n",
            "f1 score:  0.7341681483392763\n",
            "f1 score:  0.7340002764823047\n",
            "f1 score:  0.7340515266330904\n",
            "f1 score:  0.7340515266330904\n",
            "f1 score:  0.7340002764823047\n",
            "f1 score:  0.733842440079218\n",
            "f1 score:  0.7339007177514213\n",
            "f1 score:  0.7339007177514213\n",
            "f1 score:  0.733732893914062\n",
            "f1 score:  0.7339007177514213\n",
            "f1 score:  0.7339989250591238\n",
            "f1 score:  0.7342136076365494\n",
            "f1 score:  0.734114040187261\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7341707951368667\n",
            "f1 score:  0.734114040187261\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.734114040187261\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.734114040187261\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7342703501135349\n",
            "f1 score:  0.7342703501135349\n",
            "flod:  2\n",
            "f1 score:  0.6606387056793639\n",
            "f1 score:  0.6626333617367576\n",
            "f1 score:  0.6550064472360467\n",
            "f1 score:  0.6612171884507936\n",
            "f1 score:  0.667172089540629\n",
            "f1 score:  0.6759030147535959\n",
            "f1 score:  0.6739067840836434\n",
            "f1 score:  0.6828586917411764\n",
            "f1 score:  0.692597892608762\n",
            "f1 score:  0.7018415547963408\n",
            "f1 score:  0.7141163937888123\n",
            "f1 score:  0.7128121884570459\n",
            "f1 score:  0.7321922758219883\n",
            "f1 score:  0.7334126061556313\n",
            "f1 score:  0.7267870070295451\n",
            "f1 score:  0.711862653701786\n",
            "f1 score:  0.7300852086435746\n",
            "f1 score:  0.6885160850602574\n",
            "f1 score:  0.7306749913796402\n",
            "f1 score:  0.7158921665441097\n",
            "f1 score:  0.7322977147350765\n",
            "f1 score:  0.7272299401205635\n",
            "f1 score:  0.7333176061324181\n",
            "f1 score:  0.7269642126353588\n",
            "f1 score:  0.7343991647134213\n",
            "f1 score:  0.7328211527853092\n",
            "f1 score:  0.7351110703057763\n",
            "f1 score:  0.732568181861537\n",
            "f1 score:  0.7341295233849766\n",
            "f1 score:  0.7274397984486797\n",
            "f1 score:  0.7320543974795769\n",
            "f1 score:  0.7348639264516844\n",
            "f1 score:  0.734852870765028\n",
            "f1 score:  0.7314738021877544\n",
            "f1 score:  0.7319193569926696\n",
            "f1 score:  0.7332138408932981\n",
            "f1 score:  0.734512904853225\n",
            "f1 score:  0.7351241468667405\n",
            "f1 score:  0.7345354616857019\n",
            "f1 score:  0.73475238181776\n",
            "f1 score:  0.7352400617981413\n",
            "f1 score:  0.734252872576028\n",
            "f1 score:  0.7350729464396789\n",
            "f1 score:  0.735131756226993\n",
            "f1 score:  0.7351687084597812\n",
            "f1 score:  0.7349782665991297\n",
            "f1 score:  0.7350752357841156\n",
            "f1 score:  0.7351121246353128\n",
            "f1 score:  0.7353130523066472\n",
            "f1 score:  0.7353306029577799\n",
            "f1 score:  0.7350987788164843\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7352565784234915\n",
            "f1 score:  0.734645003178434\n",
            "f1 score:  0.7353130523066472\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7352519741036967\n",
            "f1 score:  0.7347279888206627\n",
            "f1 score:  0.7351251957424797\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353130523066472\n",
            "f1 score:  0.7351251957424797\n",
            "f1 score:  0.7350291428023853\n",
            "f1 score:  0.7354393796031227\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7354393796031227\n",
            "f1 score:  0.7353388655785534\n",
            "f1 score:  0.7354393796031227\n",
            "f1 score:  0.7354393796031227\n",
            "f1 score:  0.7354393796031227\n",
            "flod:  3\n",
            "f1 score:  0.7058121424705641\n",
            "f1 score:  0.7042856690862266\n",
            "f1 score:  0.7071305270963784\n",
            "f1 score:  0.7059425863964074\n",
            "f1 score:  0.7065633254396584\n",
            "f1 score:  0.7062961613413362\n",
            "f1 score:  0.7093216837014245\n",
            "f1 score:  0.7115030448090467\n",
            "f1 score:  0.7089674061681036\n",
            "f1 score:  0.7116816195157623\n",
            "f1 score:  0.7146885418366359\n",
            "f1 score:  0.7180333122097468\n",
            "f1 score:  0.7209841617000041\n",
            "f1 score:  0.7205677069317032\n",
            "f1 score:  0.72155751336159\n",
            "f1 score:  0.7238476626345601\n",
            "f1 score:  0.7239637050781456\n",
            "f1 score:  0.71772935770866\n",
            "f1 score:  0.7226511222031874\n",
            "f1 score:  0.7002100328901744\n",
            "f1 score:  0.7227360706498405\n",
            "f1 score:  0.7229116985066991\n",
            "f1 score:  0.7239331070406277\n",
            "f1 score:  0.7190812231903716\n",
            "f1 score:  0.7226005496282512\n",
            "f1 score:  0.7227550332148924\n",
            "f1 score:  0.7234287272657927\n",
            "f1 score:  0.7233900807802055\n",
            "f1 score:  0.723761192295358\n",
            "f1 score:  0.7243889412453042\n",
            "f1 score:  0.7215236956556881\n",
            "f1 score:  0.7246694459761324\n",
            "f1 score:  0.7247201520020353\n",
            "f1 score:  0.7229199401265173\n",
            "f1 score:  0.7240984672726674\n",
            "f1 score:  0.7232614827561742\n",
            "f1 score:  0.7241142670243\n",
            "f1 score:  0.7239646283556507\n",
            "f1 score:  0.7239925911487806\n",
            "f1 score:  0.723553404235408\n",
            "f1 score:  0.7240280210878183\n",
            "f1 score:  0.7253581528632328\n",
            "f1 score:  0.7239623874651313\n",
            "f1 score:  0.7240994762646874\n",
            "f1 score:  0.7234940766595868\n",
            "f1 score:  0.7241624376153974\n",
            "f1 score:  0.7241035391329893\n",
            "f1 score:  0.7240295573708523\n",
            "f1 score:  0.7248736449566051\n",
            "f1 score:  0.7244291348975763\n",
            "f1 score:  0.7239029393362889\n",
            "f1 score:  0.7241995867278792\n",
            "f1 score:  0.7241841682176969\n",
            "f1 score:  0.7243554065471951\n",
            "f1 score:  0.7246182103295423\n",
            "f1 score:  0.7242445514124006\n",
            "f1 score:  0.7243722516590122\n",
            "f1 score:  0.7250143002733864\n",
            "f1 score:  0.7250627571853373\n",
            "f1 score:  0.7251798985453132\n",
            "f1 score:  0.724856550807084\n",
            "f1 score:  0.7251762203690927\n",
            "f1 score:  0.7251499439743738\n",
            "f1 score:  0.7251762203690927\n",
            "f1 score:  0.7252286691802822\n",
            "f1 score:  0.7249646760805174\n",
            "f1 score:  0.7251762203690927\n",
            "f1 score:  0.7251173557796675\n",
            "f1 score:  0.7251194945804135\n",
            "f1 score:  0.7250649188508839\n",
            "f1 score:  0.7250343950894201\n",
            "f1 score:  0.7250081891465864\n",
            "f1 score:  0.7250081891465864\n",
            "f1 score:  0.7253136169051254\n",
            "f1 score:  0.7250526443860754\n",
            "f1 score:  0.7251952691654476\n",
            "f1 score:  0.7253044328933145\n",
            "f1 score:  0.7251618090620339\n",
            "f1 score:  0.7253044328933145\n",
            "f1 score:  0.7253581528632328\n",
            "f1 score:  0.7250081891465864\n",
            "f1 score:  0.7253581528632328\n",
            "f1 score:  0.7253044328933145\n",
            "f1 score:  0.7253581528632328\n",
            "f1 score:  0.7253044328933145\n",
            "f1 score:  0.7253581528632328\n",
            "f1 score:  0.7253581528632328\n",
            "f1 score:  0.7253581528632328\n",
            "f1 score:  0.7253581528632328\n",
            "f1 score:  0.7253581528632328\n",
            "f1 score:  0.7253581528632328\n",
            "f1 score:  0.7253581528632328\n",
            "f1 score:  0.7253581528632328\n",
            "f1 score:  0.7253581528632328\n",
            "f1 score:  0.7253581528632328\n",
            "f1 score:  0.7253581528632328\n",
            "f1 score:  0.7253581528632328\n",
            "f1 score:  0.7253581528632328\n",
            "f1 score:  0.7253581528632328\n",
            "flod:  4\n",
            "f1 score:  0.7112263864879513\n",
            "f1 score:  0.7127642876748483\n",
            "f1 score:  0.7076533210713372\n",
            "f1 score:  0.7101721474154852\n",
            "f1 score:  0.7141530806092611\n",
            "f1 score:  0.7144357656287309\n",
            "f1 score:  0.7142057943112051\n",
            "f1 score:  0.7180389527076079\n",
            "f1 score:  0.7197704624465359\n",
            "f1 score:  0.7210751244171653\n",
            "f1 score:  0.7259841406051418\n",
            "f1 score:  0.726596122081088\n",
            "f1 score:  0.7236263236202984\n",
            "f1 score:  0.7264719260474647\n",
            "f1 score:  0.7190652411540698\n",
            "f1 score:  0.7234826976906993\n",
            "f1 score:  0.724539529766182\n",
            "f1 score:  0.7261238758378732\n",
            "f1 score:  0.7233813863374724\n",
            "f1 score:  0.7278989106163912\n",
            "f1 score:  0.7275151839119388\n",
            "f1 score:  0.7214372178687171\n",
            "f1 score:  0.7266209516054158\n",
            "f1 score:  0.7273476166518367\n",
            "f1 score:  0.7272101474922082\n",
            "f1 score:  0.7281778716762976\n",
            "f1 score:  0.7251355759374672\n",
            "f1 score:  0.7271808976036794\n",
            "f1 score:  0.7283907345791203\n",
            "f1 score:  0.7280771660023087\n",
            "f1 score:  0.7271426294989795\n",
            "f1 score:  0.7264412006170535\n",
            "f1 score:  0.7283031208154783\n",
            "f1 score:  0.7277943946914478\n",
            "f1 score:  0.7283034498940805\n",
            "f1 score:  0.7282088450455545\n",
            "f1 score:  0.7288009478337588\n",
            "f1 score:  0.7274397003672278\n",
            "f1 score:  0.7284731930081215\n",
            "f1 score:  0.7280882036656647\n",
            "f1 score:  0.7284191803844825\n",
            "f1 score:  0.7282797550638298\n",
            "f1 score:  0.7289586789861726\n",
            "f1 score:  0.7284968776855111\n",
            "f1 score:  0.7286658847338069\n",
            "f1 score:  0.7283689585524006\n",
            "f1 score:  0.7287724555269829\n",
            "f1 score:  0.7288835703598301\n",
            "f1 score:  0.7285796994164003\n",
            "f1 score:  0.7287200449798052\n",
            "f1 score:  0.7287301554148722\n",
            "f1 score:  0.7285666322107734\n",
            "f1 score:  0.7285666322107734\n",
            "f1 score:  0.7287833478542275\n",
            "f1 score:  0.7285728770271751\n",
            "f1 score:  0.7285262741146273\n",
            "f1 score:  0.7286516016054905\n",
            "f1 score:  0.728912000304855\n",
            "f1 score:  0.7289303326828808\n",
            "f1 score:  0.7288302284528534\n",
            "f1 score:  0.7289303326828808\n",
            "f1 score:  0.7287768056761776\n",
            "f1 score:  0.7289303326828808\n",
            "f1 score:  0.7289303326828808\n",
            "f1 score:  0.7289303326828808\n",
            "f1 score:  0.7289303326828808\n",
            "f1 score:  0.7289303326828808\n",
            "f1 score:  0.7289303326828808\n",
            "f1 score:  0.7287768056761776\n",
            "f1 score:  0.7287768056761776\n",
            "f1 score:  0.7287768056761776\n",
            "f1 score:  0.7287768056761776\n",
            "f1 score:  0.7288585701015661\n",
            "f1 score:  0.7288585701015661\n",
            "f1 score:  0.7289586789861726\n",
            "f1 score:  0.7289586789861726\n",
            "f1 score:  0.7289051787823545\n",
            "f1 score:  0.7289586789861726\n",
            "flod:  5\n",
            "f1 score:  0.7300397574104318\n",
            "f1 score:  0.7290993007566491\n",
            "f1 score:  0.7288873894143548\n",
            "f1 score:  0.7303421850718689\n",
            "f1 score:  0.7286305216207697\n",
            "f1 score:  0.7297828420026639\n",
            "f1 score:  0.7280407482903689\n",
            "f1 score:  0.7299047701518931\n",
            "f1 score:  0.7293361760688691\n",
            "f1 score:  0.7303193212895803\n",
            "f1 score:  0.7290122482830815\n",
            "f1 score:  0.7298454726449474\n",
            "f1 score:  0.7300161899928952\n",
            "f1 score:  0.7297729420101159\n",
            "f1 score:  0.7299295255156916\n",
            "f1 score:  0.7303746853670305\n",
            "f1 score:  0.730564479241916\n",
            "f1 score:  0.7301908893270448\n",
            "f1 score:  0.7306084751533745\n",
            "f1 score:  0.7308260499304251\n",
            "f1 score:  0.7308819592364318\n",
            "f1 score:  0.7302227274292562\n",
            "f1 score:  0.7307837339851669\n",
            "f1 score:  0.731224773945966\n",
            "f1 score:  0.731157711299903\n",
            "f1 score:  0.7307654477298576\n",
            "f1 score:  0.7306430620439803\n",
            "f1 score:  0.7304852825333694\n",
            "f1 score:  0.7313072306903905\n",
            "f1 score:  0.731224532305032\n",
            "f1 score:  0.7313533162730902\n",
            "f1 score:  0.7311956478533294\n",
            "f1 score:  0.731615754930263\n",
            "f1 score:  0.7314111857219241\n",
            "f1 score:  0.7313075542092459\n",
            "f1 score:  0.7315411882790416\n",
            "f1 score:  0.7315050426558652\n",
            "f1 score:  0.7316883340696271\n",
            "f1 score:  0.731488070385126\n",
            "f1 score:  0.7313219428637727\n",
            "f1 score:  0.7314087304345582\n",
            "f1 score:  0.7313280518473593\n",
            "f1 score:  0.7318240362843448\n",
            "f1 score:  0.7315018746604126\n",
            "f1 score:  0.7315272350876857\n",
            "f1 score:  0.7318335890906876\n",
            "f1 score:  0.7314187583252574\n",
            "f1 score:  0.7314814380676061\n",
            "f1 score:  0.7316283715267402\n",
            "f1 score:  0.7317409006985751\n",
            "f1 score:  0.7317641195292911\n",
            "f1 score:  0.7317041956743512\n",
            "f1 score:  0.7317641195292911\n",
            "f1 score:  0.7317873071847224\n",
            "f1 score:  0.7317114836151593\n",
            "f1 score:  0.7318704319013868\n",
            "f1 score:  0.7318704319013868\n",
            "f1 score:  0.7318495136257376\n",
            "f1 score:  0.7317641195292911\n",
            "f1 score:  0.7318104636951211\n",
            "f1 score:  0.7318704319013868\n",
            "f1 score:  0.7317041956743512\n",
            "f1 score:  0.7317041956743512\n",
            "f1 score:  0.7318704319013868\n",
            "f1 score:  0.731694369390017\n",
            "f1 score:  0.7317873071847224\n",
            "f1 score:  0.7317409006985751\n",
            "f1 score:  0.7317873071847224\n",
            "f1 score:  0.7318704319013868\n",
            "f1 score:  0.7318704319013868\n",
            "f1 score:  0.7317873071847224\n",
            "f1 score:  0.7317641195292911\n",
            "f1 score:  0.7318704319013868\n",
            "f1 score:  0.7318704319013868\n",
            "f1 score:  0.7318704319013868\n",
            "f1 score:  0.7318704319013868\n",
            "f1 score:  0.7318704319013868\n",
            "f1 score:  0.7318704319013868\n",
            "f1 score:  0.7318704319013868\n",
            "f1 score:  0.7318704319013868\n",
            "f1 score:  0.7318704319013868\n",
            "f1 score:  0.7318704319013868\n",
            "f1 score:  0.7318704319013868\n",
            "flod:  6\n",
            "f1 score:  0.7097524494931289\n",
            "f1 score:  0.7126426818826626\n",
            "f1 score:  0.7048184656054793\n",
            "f1 score:  0.7110190290227827\n",
            "f1 score:  0.715602390156363\n",
            "f1 score:  0.720235108716718\n",
            "f1 score:  0.7192395716344627\n",
            "f1 score:  0.7223937855361297\n",
            "f1 score:  0.7271007042632304\n",
            "f1 score:  0.7292895312363893\n",
            "f1 score:  0.7328586753455416\n",
            "f1 score:  0.7341085699898375\n",
            "f1 score:  0.7319913268192791\n",
            "f1 score:  0.7324320877710474\n",
            "f1 score:  0.7243734849931084\n",
            "f1 score:  0.7325461728665384\n",
            "f1 score:  0.7249230945167375\n",
            "f1 score:  0.7346759190348001\n",
            "f1 score:  0.7335311472596988\n",
            "f1 score:  0.7334542089387015\n",
            "f1 score:  0.7339991055504845\n",
            "f1 score:  0.7340530312467903\n",
            "f1 score:  0.7328240580375844\n",
            "f1 score:  0.7343172268103473\n",
            "f1 score:  0.7338079968847576\n",
            "f1 score:  0.7352196466313957\n",
            "f1 score:  0.7347557261555328\n",
            "f1 score:  0.7341198029153998\n",
            "f1 score:  0.7341828923132264\n",
            "f1 score:  0.7346000718438517\n",
            "f1 score:  0.7350238253898268\n",
            "f1 score:  0.7348375618462079\n",
            "f1 score:  0.7343819918117229\n",
            "f1 score:  0.7350422296046366\n",
            "f1 score:  0.734844720094305\n",
            "f1 score:  0.7347039865036601\n",
            "f1 score:  0.7348382112775814\n",
            "f1 score:  0.7347618667709351\n",
            "f1 score:  0.7348088613620751\n",
            "f1 score:  0.7352340031153295\n",
            "f1 score:  0.7348792603528701\n",
            "f1 score:  0.7350639617492764\n",
            "f1 score:  0.7347649817852621\n",
            "f1 score:  0.7348574135769937\n",
            "f1 score:  0.7347174410949667\n",
            "f1 score:  0.7349444034457017\n",
            "f1 score:  0.7349227574832788\n",
            "f1 score:  0.7351523864224165\n",
            "f1 score:  0.7352393343247073\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7352263914539314\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7351957683455893\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7350260950057734\n",
            "f1 score:  0.7352393343247073\n",
            "f1 score:  0.7352026021330974\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "f1 score:  0.7353882229418557\n",
            "flod:  7\n",
            "f1 score:  0.6621024191427995\n",
            "f1 score:  0.6605563561958193\n",
            "f1 score:  0.6667457376939475\n",
            "f1 score:  0.6605126457962095\n",
            "f1 score:  0.6658185851458861\n",
            "f1 score:  0.6692416015617471\n",
            "f1 score:  0.6731839245930885\n",
            "f1 score:  0.6749881115447881\n",
            "f1 score:  0.6792531889524064\n",
            "f1 score:  0.6812059350820835\n",
            "f1 score:  0.6861655908026686\n",
            "f1 score:  0.6931933121339848\n",
            "f1 score:  0.7042037638789481\n",
            "f1 score:  0.7059853597423437\n",
            "f1 score:  0.7160932873096414\n",
            "f1 score:  0.7234857464776967\n",
            "f1 score:  0.7155972251541005\n",
            "f1 score:  0.7244230525190875\n",
            "f1 score:  0.7091601238040881\n",
            "f1 score:  0.7216939903705253\n",
            "f1 score:  0.7070177147571908\n",
            "f1 score:  0.7268745751204267\n",
            "f1 score:  0.7117477320203296\n",
            "f1 score:  0.7232837319667488\n",
            "f1 score:  0.7192728814509546\n",
            "f1 score:  0.7270726560208477\n",
            "f1 score:  0.727087529398248\n",
            "f1 score:  0.7236149566106084\n",
            "f1 score:  0.7260802113756085\n",
            "f1 score:  0.7262799346405052\n",
            "f1 score:  0.7260530701146929\n",
            "f1 score:  0.72574978552014\n",
            "f1 score:  0.7253273424680531\n",
            "f1 score:  0.7251289196456105\n",
            "f1 score:  0.7264056210066311\n",
            "f1 score:  0.7245351327094878\n",
            "f1 score:  0.726362498345738\n",
            "f1 score:  0.7269804638658212\n",
            "f1 score:  0.7268839848575589\n",
            "f1 score:  0.7275115553498935\n",
            "f1 score:  0.7248429413311738\n",
            "f1 score:  0.7265020964663638\n",
            "f1 score:  0.7267617565353092\n",
            "f1 score:  0.7270889894601478\n",
            "f1 score:  0.7279818320573656\n",
            "f1 score:  0.7273693065230944\n",
            "f1 score:  0.7284964547542053\n",
            "f1 score:  0.727724559960623\n",
            "f1 score:  0.7287709580938045\n",
            "f1 score:  0.7279168478249467\n",
            "f1 score:  0.72863115845899\n",
            "f1 score:  0.7281829315553932\n",
            "f1 score:  0.7280925751730317\n",
            "f1 score:  0.7281859347220073\n",
            "f1 score:  0.7284964547542053\n",
            "f1 score:  0.7273294369091553\n",
            "f1 score:  0.7278836272664795\n",
            "f1 score:  0.727664714122581\n",
            "f1 score:  0.7286627363146237\n",
            "f1 score:  0.7275267650376563\n",
            "f1 score:  0.727714511292015\n",
            "f1 score:  0.7283633890987541\n",
            "f1 score:  0.7283898029855664\n",
            "f1 score:  0.7283385124038896\n",
            "f1 score:  0.7284698497266268\n",
            "f1 score:  0.7274212772272101\n",
            "f1 score:  0.728571548012989\n",
            "f1 score:  0.7284775867560315\n",
            "f1 score:  0.728662895737712\n",
            "f1 score:  0.7273964805206283\n",
            "f1 score:  0.7287690654810858\n",
            "f1 score:  0.7286712437094183\n",
            "f1 score:  0.7287690654810858\n",
            "f1 score:  0.728760744860141\n",
            "f1 score:  0.7288439224790504\n",
            "f1 score:  0.7287709580938045\n",
            "f1 score:  0.7281198862626\n",
            "f1 score:  0.7286379789102043\n",
            "f1 score:  0.728662895737712\n",
            "f1 score:  0.728662895737712\n",
            "f1 score:  0.7285195281976274\n",
            "f1 score:  0.7286877792881352\n",
            "f1 score:  0.728662895737712\n",
            "f1 score:  0.728662895737712\n",
            "f1 score:  0.728662895737712\n",
            "f1 score:  0.728662895737712\n",
            "f1 score:  0.728662895737712\n",
            "f1 score:  0.728662895737712\n",
            "f1 score:  0.728662895737712\n",
            "f1 score:  0.728662895737712\n",
            "f1 score:  0.728662895737712\n",
            "f1 score:  0.728760744860141\n",
            "f1 score:  0.728760744860141\n",
            "f1 score:  0.7287358209371827\n",
            "f1 score:  0.7288439224790504\n",
            "f1 score:  0.7287358209371827\n",
            "f1 score:  0.7288439224790504\n",
            "f1 score:  0.7287358209371827\n",
            "f1 score:  0.7288439224790504\n",
            "flod:  8\n",
            "f1 score:  0.7062333051050197\n",
            "f1 score:  0.7068847826902562\n",
            "f1 score:  0.7025728431451336\n",
            "f1 score:  0.7080144836376245\n",
            "f1 score:  0.7116648984531019\n",
            "f1 score:  0.7154870448131061\n",
            "f1 score:  0.7146104418935099\n",
            "f1 score:  0.7160771480825737\n",
            "f1 score:  0.7210559579432596\n",
            "f1 score:  0.7247333905296877\n",
            "f1 score:  0.724687357340803\n",
            "f1 score:  0.7266487867609097\n",
            "f1 score:  0.7276731639465565\n",
            "f1 score:  0.7274703459799259\n",
            "f1 score:  0.7247483741867168\n",
            "f1 score:  0.7187536876263834\n",
            "f1 score:  0.7252412642003203\n",
            "f1 score:  0.7257135436186211\n",
            "f1 score:  0.7291424322098106\n",
            "f1 score:  0.7303004125466858\n",
            "f1 score:  0.724765541725754\n",
            "f1 score:  0.7279748073664513\n",
            "f1 score:  0.7274409471312243\n",
            "f1 score:  0.7282789396956048\n",
            "f1 score:  0.729288574896548\n",
            "f1 score:  0.7296496136709472\n",
            "f1 score:  0.7295286785156844\n",
            "f1 score:  0.7311074596075168\n",
            "f1 score:  0.7293803138625171\n",
            "f1 score:  0.7275918107765801\n",
            "f1 score:  0.7304168166383515\n",
            "f1 score:  0.7296691462125763\n",
            "f1 score:  0.7298976748124374\n",
            "f1 score:  0.7305047464469832\n",
            "f1 score:  0.7309122442197062\n",
            "f1 score:  0.7286898016394942\n",
            "f1 score:  0.7313931917067347\n",
            "f1 score:  0.7292940220487517\n",
            "f1 score:  0.7316356638755743\n",
            "f1 score:  0.7305699483377253\n",
            "f1 score:  0.7311100482444116\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7307314378616562\n",
            "f1 score:  0.7307788646828076\n",
            "f1 score:  0.7316540985545132\n",
            "f1 score:  0.7310247167817664\n",
            "f1 score:  0.7317833434201635\n",
            "f1 score:  0.730996045718757\n",
            "f1 score:  0.7312271947776002\n",
            "f1 score:  0.7317833434201635\n",
            "f1 score:  0.7315834382709641\n",
            "f1 score:  0.731770083276667\n",
            "f1 score:  0.7313990290761213\n",
            "f1 score:  0.7316206978182893\n",
            "f1 score:  0.7316088387167335\n",
            "f1 score:  0.7318517480245451\n",
            "f1 score:  0.7316392928652548\n",
            "f1 score:  0.7316405124405324\n",
            "f1 score:  0.7318636906287375\n",
            "f1 score:  0.7319008265916945\n",
            "f1 score:  0.7318061759993265\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7319008265916945\n",
            "f1 score:  0.7319008265916945\n",
            "f1 score:  0.7319236782948697\n",
            "f1 score:  0.731758064441692\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7319008265916945\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7319008265916945\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "f1 score:  0.7320065043584929\n",
            "flod:  9\n",
            "f1 score:  0.7079809287257867\n",
            "f1 score:  0.7110203950974096\n",
            "f1 score:  0.7058916865276125\n",
            "f1 score:  0.7063935981392547\n",
            "f1 score:  0.7100797848215694\n",
            "f1 score:  0.7133902441747318\n",
            "f1 score:  0.7160443332148416\n",
            "f1 score:  0.715287638972042\n",
            "f1 score:  0.7163136221495655\n",
            "f1 score:  0.7188335552966274\n",
            "f1 score:  0.7193988096480662\n",
            "f1 score:  0.7241214008948975\n",
            "f1 score:  0.7220963758130496\n",
            "f1 score:  0.7264485807084133\n",
            "f1 score:  0.7263543969960325\n",
            "f1 score:  0.7296858969412038\n",
            "f1 score:  0.729684852363058\n",
            "f1 score:  0.7294052663201965\n",
            "f1 score:  0.7272549944008461\n",
            "f1 score:  0.7301240665325365\n",
            "f1 score:  0.725215833126299\n",
            "f1 score:  0.7293253504055025\n",
            "f1 score:  0.7293119710525611\n",
            "f1 score:  0.7327442934727749\n",
            "f1 score:  0.7318478795702114\n",
            "f1 score:  0.7282314242778961\n",
            "f1 score:  0.7322344023357106\n",
            "f1 score:  0.7284329701556714\n",
            "f1 score:  0.7323494014511326\n",
            "f1 score:  0.7326050040252157\n",
            "f1 score:  0.7291610744561253\n",
            "f1 score:  0.7323804978148813\n",
            "f1 score:  0.7314850934627399\n",
            "f1 score:  0.7331028028704356\n",
            "f1 score:  0.7315249511904344\n",
            "f1 score:  0.732156411843838\n",
            "f1 score:  0.7320613705644358\n",
            "f1 score:  0.732810610978461\n",
            "f1 score:  0.7326485402655241\n",
            "f1 score:  0.7322908523863113\n",
            "f1 score:  0.7327392504844158\n",
            "f1 score:  0.7330492030652745\n",
            "f1 score:  0.732730223109452\n",
            "f1 score:  0.7328358736374362\n",
            "f1 score:  0.7332340376830014\n",
            "f1 score:  0.7326559523116342\n",
            "f1 score:  0.7328208805547375\n",
            "f1 score:  0.7332900828552016\n",
            "f1 score:  0.7330809331671944\n",
            "f1 score:  0.7331304449305883\n",
            "f1 score:  0.7330188578395817\n",
            "f1 score:  0.7332138936069249\n",
            "f1 score:  0.7333094220227295\n",
            "f1 score:  0.73306126260068\n",
            "f1 score:  0.7328658920218242\n",
            "f1 score:  0.7333296543416178\n",
            "f1 score:  0.7332214971435279\n",
            "f1 score:  0.7331559317682226\n",
            "f1 score:  0.7332168194044429\n",
            "f1 score:  0.7331858607630407\n",
            "f1 score:  0.7331559317682226\n",
            "f1 score:  0.733281802049676\n",
            "f1 score:  0.7333149653399301\n",
            "f1 score:  0.7330215987967558\n",
            "f1 score:  0.7332314714918974\n",
            "f1 score:  0.7333675432669637\n",
            "f1 score:  0.7330215987967558\n",
            "f1 score:  0.7333521526917753\n",
            "f1 score:  0.7334278681095138\n",
            "f1 score:  0.733534482500929\n",
            "f1 score:  0.7334278681095138\n",
            "f1 score:  0.733234664809178\n",
            "f1 score:  0.7334131421613904\n",
            "f1 score:  0.7334649909586543\n",
            "f1 score:  0.7332742205425599\n",
            "f1 score:  0.7335113499025989\n",
            "f1 score:  0.7335948450363085\n",
            "f1 score:  0.7334503094748026\n",
            "f1 score:  0.7333675432669637\n",
            "f1 score:  0.7335948450363085\n",
            "f1 score:  0.7335113499025989\n",
            "f1 score:  0.7335113499025989\n",
            "f1 score:  0.7335948450363085\n",
            "f1 score:  0.7335113499025989\n",
            "f1 score:  0.7335113499025989\n",
            "f1 score:  0.7335113499025989\n",
            "f1 score:  0.7335113499025989\n",
            "f1 score:  0.7335948450363085\n",
            "f1 score:  0.7335113499025989\n",
            "f1 score:  0.7335948450363085\n",
            "f1 score:  0.7333814981041015\n",
            "f1 score:  0.7335113499025989\n",
            "f1 score:  0.7335948450363085\n",
            "f1 score:  0.7335948450363085\n",
            "f1 score:  0.7335948450363085\n",
            "f1 score:  0.7333814981041015\n",
            "f1 score:  0.7335948450363085\n",
            "f1 score:  0.7335948450363085\n",
            "f1 score:  0.7335948450363085\n",
            "f1 score:  0.7335948450363085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLpUuFGwQA8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "coef = opr.coef_['x']\n",
        "sub = np.average(test_preds, axis=0)\n",
        "sub = opr.predict(sub,coef)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK9LAy1zSgec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sub['y'] = sub-1\n",
        "df_sub.astype('int64').to_csv('test_sub.csv',index=False, encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q-YWNO3JWXH",
        "colab_type": "code",
        "outputId": "6766fa53-a267-44ce-dbcc-9bfeb3b534e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "target = np.argmax(valid_outputs,axis=1)\n",
        "preds = np.argmax(valid_preds[4],axis=1)\n",
        "tf.compat.v1.confusion_matrix(target,preds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[1723, 1488,  170],\n",
              "       [ 629, 9265, 1629],\n",
              "       [  44, 1052, 3982]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTlqXvH1iViM",
        "colab_type": "code",
        "outputId": "f71e2dfc-5081-4b91-f682-194a2c0e43e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri May  1 06:49:57 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}